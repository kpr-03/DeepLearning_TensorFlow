{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpr-03/DeepLearning_TensorFlow/blob/main/O3_introduction_to_computer__vision_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iraraOra0sQz"
      },
      "source": [
        "# Introduction to Convolutional Neural Networks And Computer Vision with TensorFlow.\n",
        "\n",
        "Computer vision is the practice of writing algorithms which can discover patterns in visual data.Such as the camera of a self- driving car recognizing the car in front."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6iVcRO66EC"
      },
      "source": [
        "## Get the data\n",
        "\n",
        "Because convolutional neural networks work so well with images, to learn more about them, we're going to start with a dataset of images.\n",
        "\n",
        "The images we're going to work with are from the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/), a collection of 101 different categories of 101,000 (1000 images per category) real-world images of food dishes.\n",
        "\n",
        "To begin, we're only going to use two of the categories, pizza ðŸ• and steak ðŸ¥© and build a binary classifier.\n",
        "\n",
        "> ðŸ”‘ **Note:** To prepare the data we're using, preprocessing steps such as, moving the images into different subset folders, have been done. To see these preprocessing steps check out [the preprocessing notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb).\n",
        "\n",
        "We'll download the `pizza_steak` subset .zip file and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_yoK_Wh6_8S"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_q0BTl7xvJ"
      },
      "outputs": [],
      "source": [
        "# unzip the downloaded file\n",
        "zip_ref =zipfile.ZipFile(\"pizza_steak.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8PLj-CE8RZs"
      },
      "source": [
        "## Inspect the data\n",
        "\n",
        "A very crucial step at the beginning of any machine learning project is becoming one with data.\n",
        "\n",
        "And for a computer vision project...this usually means visualizing many samples of your data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwCTCeQ_DC3X"
      },
      "outputs": [],
      "source": [
        "!ls pizza_steak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AOqy3pDGpz"
      },
      "outputs": [],
      "source": [
        "!ls pizza_steak/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYd6AuxBDU9X"
      },
      "outputs": [],
      "source": [
        "!ls pizza_steak/train/steak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RW5ZGGYEBJu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Md0pgMsEm8Q"
      },
      "outputs": [],
      "source": [
        "# the extra file in our pizza_steak directory is \".DS_store\"\n",
        "!ls -la pizza_steak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIV7En5OE1oI"
      },
      "outputs": [],
      "source": [
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train= len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "num_steak_images_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-1RSub-LjJp"
      },
      "source": [
        "To visualize our images, first let's get the class names programatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUdqI6EULgRh"
      },
      "outputs": [],
      "source": [
        "# Get the class names programatically\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir =pathlib.Path(\"pizza_steak/train\")\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # creted a list of class_names from the subdirectory\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjKU_Km7MVOZ"
      },
      "outputs": [],
      "source": [
        "# Let's visualize our images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir,target_class):\n",
        "  #setup the target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "  #Get a random image path\n",
        "  random_image =random.sample(os.listdir(target_folder),1)\n",
        "  print(random_image)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  print(f\"image shape : {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RWF77VTQIA0"
      },
      "outputs": [],
      "source": [
        "# view a random image from training data set\n",
        "img= view_random_image(target_dir=\"pizza_steak/train/\",\n",
        "                       target_class=\"pizza\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D19qcEMGQZ5l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wClkCs8CRRzs"
      },
      "outputs": [],
      "source": [
        "# View the image shape\n",
        "img.shape # returns width,height,colour channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpILrL3zR4Ap"
      },
      "outputs": [],
      "source": [
        "# Get all the pixel values between 0 & 1\n",
        "img/255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8Wi2qcYWSd"
      },
      "source": [
        "## An End-to-End Example\n",
        "Let's build a convolutional neural network to find patterns in our images,more specifically we neea a way to :\n",
        "* Load our images\n",
        "* Preprocess our images\n",
        "* Build a CNN to find patterns in our images\n",
        "* Compile our CNN\n",
        "* Fit the CNN to our training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GisL5QdLSdAi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocessing data(get all of the pixel values between 0 & 1,also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale= 1./255)\n",
        "\n",
        "# Set up path to our data directories\n",
        "train_dir =  \"/content/pizza_steak/train\"\n",
        "test_dir = \"pizza_steak/test\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               batch_size = 32,\n",
        "                                               target_size=(224,224),\n",
        "                                               class_mode = \"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data =valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                               batch_size = 32,\n",
        "                                               target_size=(224,224),\n",
        "                                               class_mode = \"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Build a CNN model(same as the TINY VGG on the CNN explainer website)\n",
        "model_1= tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=3,\n",
        "                           activation=\"relu\",\n",
        "                           input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                              padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compile our CNN\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 =model_1.fit(train_data,\n",
        "                       epochs=5,\n",
        "                       steps_per_epoch=len(train_data),\n",
        "                       validation_data=valid_data,\n",
        "                       validation_steps=len(valid_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtWIZtfBhsPU"
      },
      "outputs": [],
      "source": [
        "# Get the model summary\n",
        "model_1.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEayeyOqfRw"
      },
      "source": [
        "## Using the same model as before\n",
        "\n",
        "The model we're building is from the [Tensorflow Playground](\n",
        "  https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.001&regularizationRate=0&noise=0&networkShape=4,2&seed=0.46097&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKQAelczrD3P"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model to replicate the Tensorflow Model\n",
        "model_2= tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Dense(4,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "#Fit the model\n",
        "history_2= model_2.fit(train_data,\n",
        "                       epochs=5,\n",
        "                       steps_per_epoch=len(train_data),\n",
        "                       validation_data=valid_data,\n",
        "                       validation_steps=len(valid_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxJr4SAptQws"
      },
      "outputs": [],
      "source": [
        "#get summary of model_2\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JcHqpkwuJfF"
      },
      "source": [
        "Despite having 20x more parameters than our CNN(model_1),model_2 performs terribly...let's try to improve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_lH3lVfVeYE"
      },
      "outputs": [],
      "source": [
        "#set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create the model(same as above but let's step it up a notch)\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "\n",
        "history_3 = model_3.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYW7dV6WXQpI"
      },
      "outputs": [],
      "source": [
        "# Get a summary of model_3\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOue6JoMXwrc"
      },
      "source": [
        "ðŸ”‘ **Note:** You can think of trainable parameters as *patterns a model can learn from data*. Intuitiely, you might think more is better. And in some cases it is. But in this case, the difference here is in the two different styles of model we're using. Where a series of dense layers have a number of different learnable parameters connected to each other and hence a higher number of possible learnable patterns, **a convolutional neural network seeks to sort out and learn the most important patterns in an image**. So even though there are less learnable parameters in our convolutional neural network, these are often more helpful in decphering between different **features** in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mU5UrCZcbx9"
      },
      "source": [
        "## binary classification : Let's break it down\n",
        "1. Become one with data(visualize,visualize,visualize)\n",
        "2. Preprocess the data(prepared it for our model,the main step here was scaling/normalizing)\n",
        "3. Created a model(start with a baseline).\n",
        "4. Fit the model\n",
        "5. Evaluate the model\n",
        "6. Adjust the different parameters and improve the model(try to beat our baseline)\n",
        "7. Repeat untill satisfied(experiment,experiment,experiment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT9hY5r0dP0l"
      },
      "source": [
        "## Become one with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFklOuHAdUYQ"
      },
      "outputs": [],
      "source": [
        "# visualize the data\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "steak_img = view_random_image(\"pizza_steak/train/\",\"steak\")\n",
        "plt.subplot(1,2,2)\n",
        "pizza_img = view_random_image(\"pizza_steak/train/\",\"pizza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzYzA479fDzl"
      },
      "source": [
        "### 2. Preprocess the data(prepare it for a model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygdhSmxRgGzI"
      },
      "outputs": [],
      "source": [
        "# Define directory datasets path\n",
        "train_dir =\"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prhH1VHggVGD"
      },
      "source": [
        "Our next step is to turn data into **batches**...\n",
        "\n",
        "A batch is a small subset of data,Rather than at all ~10,000 images at one time,a model might only look at 32 at a time.\n",
        "\n",
        "It does this for couple of reasons:\n",
        "1. 10,000 images (or more) might not fit into the memory of your processor(GPU).\n",
        "2. Tryin to learn the patterns in 10,000 images in one hit could result in the model not being able to learn very well.\n",
        "\n",
        "why 32?\n",
        "\n",
        "Beacause 32 is good for your health.. https://twitter.com/ylecun/status/989610208497360896?s=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7-Soou9hEyJ"
      },
      "outputs": [],
      "source": [
        "# create train and test data generators and rescale the data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42sChoR4madE"
      },
      "outputs": [],
      "source": [
        "# Load in our image data from directories and turn them into batches\n",
        "train_data =train_datagen.flow_from_directory(directory = train_dir, # target directory of images\n",
        "                                              target_size=(224,224), # target size of images(height,width)\n",
        "                                              class_mode=\"binary\", # type of data you are working with\n",
        "                                              batch_size=32) # size of minibatches to load data into\n",
        "test_data =test_datagen.flow_from_directory(test_dir,\n",
        "                                            target_size=(224,224),\n",
        "                                            class_mode=\"binary\",\n",
        "                                            batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nROQpKkJoQkU"
      },
      "outputs": [],
      "source": [
        "# get a sample of training data batch\n",
        "images,labels =train_data.next() # get the 'next' batch of images/labels i8n train data\n",
        "len(images),len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiWarxg2osty"
      },
      "outputs": [],
      "source": [
        "# how many batches are there\n",
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtYz1kApoxiL"
      },
      "outputs": [],
      "source": [
        "# Get the first two images\n",
        "images[:2],images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivpSH0wo8Sj"
      },
      "outputs": [],
      "source": [
        "images[7].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oufww7aEpQTh"
      },
      "outputs": [],
      "source": [
        "# view the first batch labels\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtSEemX0pdNp"
      },
      "source": [
        "3. Create a CNN model(start with a baseline)\n",
        "\n",
        " A baseline is a relatively simple model or existing result than you setup when beginning a mchine learning experiment and then as you keep experimenting ,you try to beat the baseline.\n",
        "\n",
        " ðŸ”‘**Note:** In deep learning there is almost an infinite amount of architectures you could create.So one of the best ways to get started is to start with something simple and see if ut works on your data and then introduce complexiety as required(e.g look at which current model is performing best in the field of your problem)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHEtedbpsS7C"
      },
      "outputs": [],
      "source": [
        "# Make the creating of our model  alittle easier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Activation\n",
        "from tensorflow.keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFoqQb7Hs8Sv"
      },
      "outputs": [],
      "source": [
        "# Create the model(this will be our baseline, a 3 layer convolutional network)\n",
        "model_4 = Sequential([\n",
        "    Conv2D(filters=10,# filter is the number of sliding windows going across an input(higher=more complex model)\n",
        "           kernel_size=3,# the size of the sliding window going across an input\n",
        "           strides=1, # the size of the step the sliding window takes across an input\n",
        "           padding=\"valid\", # if 'same',output is same as input shape,if \"valid\",output shape gets compressed\n",
        "           activation=\"relu\",\n",
        "           input_shape=(224,224,3)), # input layer(specify input shape)\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    Flatten(),\n",
        "    Dense(1,activation=\"sigmoid\") # output layer( working with binary classification so only 1 output neuron)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CclJW9v_Phti"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KxopEveMA1s"
      },
      "outputs": [],
      "source": [
        "#get the summary of our model_4\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9L9wxjQx74"
      },
      "source": [
        "### 4. Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCJh6wjlQ6oA"
      },
      "outputs": [],
      "source": [
        "# check the lengths of training and test data generators\n",
        "len(train_data),len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwIdw-94RWFW"
      },
      "outputs": [],
      "source": [
        "# fit the model\n",
        "history_4 = model_4.fit(train_data, # this is a combination of labels and sample data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch = len(train_data),\n",
        "                        validation_data =test_data,\n",
        "                        validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox1DHUmsR_Rv"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0UA1tD8SWQh"
      },
      "outputs": [],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pgS0Q9SbBk"
      },
      "source": [
        "### 5. Evaluating our model\n",
        "It looks liek our model is learning something ,lket's evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWOKO_U_TR57"
      },
      "outputs": [],
      "source": [
        "# Let's plot the training curve's\n",
        "import pandas as pd\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10,7));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGscgBAhTd_B"
      },
      "outputs": [],
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns spearate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss= history.history[\"loss\"]\n",
        "  val_loss =history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy= history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs=range(len(history.history[\"loss\"])) # how many epochs did we run for?\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs,loss,label=\"training_loss\")\n",
        "  plt.plot(epochs,val_loss,label=\"val_loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs,accuracy,label=\"training_accuracy\")\n",
        "  plt.plot(epochs,val_accuracy,label=\"val_accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bMB_jnOWDY5"
      },
      "source": [
        "> ðŸ”‘**Note:** When a model's **validation loss starts to increase**,it's likely that the model is **overfitting** the training dataset.This means,it's learning the patterns in the training dataset *too well* and thus model's ability to generalize to unseen data will be diminished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRipZW6VVVOy"
      },
      "outputs": [],
      "source": [
        "# check out the loss and accuracy of model_4\n",
        "plot_loss_curves(history_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgtCogkcVjnK"
      },
      "source": [
        "**Note:** Ideally the two loss curves(training and validation) will be very similar to each other (training loass and validation loss decreasing at similar rates),when there are large differences your model may be **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBEUwQr8X3a5"
      },
      "source": [
        "### 6. Adjust the model parameters\n",
        "Fitting a machine learning model comes in 3 steps:\n",
        "0. Create a baseline\n",
        "1. Beat the baseline by overfitting a larger model\n",
        "2. Reduce overfitting\n",
        "\n",
        "Ways to induce overfitting:\n",
        "* Increase the number of conv layers\n",
        "* Increase the number of conv filters\n",
        "* Add another dense layer to the output of our flattened layer\n",
        "\n",
        "Reduce Overfitting:\n",
        "* Add data augmentation\n",
        "* Add regularization layers(such as MaxPool2D)\n",
        "* Add more data...\n",
        "\n",
        "> ðŸ”‘**Note:** Reducing overfitting is also known as **regularization**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg-LGTfbZimu"
      },
      "outputs": [],
      "source": [
        "# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)\n",
        "model_5 = Sequential([\n",
        "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYIIivIRlH5_"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btDTkwA8lWUt"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "history_5 =model_5.fit(train_data,\n",
        "                       epochs=5,\n",
        "                       steps_per_epoch=len(train_data),\n",
        "                       validation_data=test_data,\n",
        "                       validation_steps=len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnsY_KoWlqw5"
      },
      "outputs": [],
      "source": [
        "# Get a summary of our model with max pooling\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yekoiniZmAbK"
      },
      "outputs": [],
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGXsLa-mRbp"
      },
      "source": [
        "### Opening bour bag of tricks and finding data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhE1VPoFnWnB"
      },
      "outputs": [],
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2, # how much do you want to rotate an image?\n",
        "                                             shear_range=0.2,# how much do you want to shear an image?\n",
        "                                             zoom_range=0.2,# zoom in randomly on an image\n",
        "                                             width_shift_range=0.2, # Move your data to x-axis\n",
        "                                             height_shift_range=0.3, # move your image around y-axis\n",
        "                                             horizontal_flip=True) # Do you want to flip your image?\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation\n",
        "train_datagen =ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation nfor the test dataset\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvaAgQ_eoupe"
      },
      "source": [
        "> â“**Question:** what is data augmentation?\n",
        "Data augmentation is the process of altering our training data ,leading it to have more density and in turn allowing our models to learn  more generalizable(hopefully) patterns.Altering might mean adjusting the rotation of an image,flippinfg it,cropping it or something similar.\n",
        "\n",
        "Let's write some code to visualize data augmentation.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM5729cwooPD"
      },
      "outputs": [],
      "source": [
        "# Import data and augment it from training directory\n",
        "print(\"Augmented training data:\")\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224,224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"binary\",\n",
        "                                                                   shuffle=False) # for demonstration purposes only\n",
        "# create non-augmented train data batches\n",
        "print(\"Non-augmented training data:\")\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"binary\",\n",
        "                                               shuffle =False)\n",
        "# create non-augmented test data batches\n",
        "print(\"Non-augmented test data:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224,224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"binary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-ZrwJLPuMjL"
      },
      "source": [
        "ðŸ”‘**Note:** Data augmentation is usually only performed on the training data.Using `ImageDataGenerator` built-in data augmentation parameters our images are left as they are in the directories but modeified as they're loaded into the model.\n",
        "\n",
        "Finally...let's visualize some augmented data!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6GAAfHysavx"
      },
      "outputs": [],
      "source": [
        "# Get sample data batches\n",
        "images,labels = train_data.next()\n",
        "augmented_images , augmented_labels = train_data_augmented.next() # note: labels aren't augmented...only data(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZs7vXJSvk24"
      },
      "outputs": [],
      "source": [
        "# show the original image and augmented image\n",
        "import random\n",
        "random_number = random.randint(0,32)# our batch size are 32...\n",
        "print(f\"showing image number: {random_number}\")\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(f\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(f\"Augmented image\")\n",
        "plt.axis(False);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqv0vtoRyad4"
      },
      "source": [
        "Now we've seen what augmented training data looks lie,let's build a model and see how it works with same model as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY47TozCwhIh"
      },
      "outputs": [],
      "source": [
        "# create the model(same as model_5)\n",
        "model_6= Sequential([\n",
        "    Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "    MaxPool2D(pool_size=2),# reducr number of features by half\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_6=model_6.fit(train_data_augmented,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data_augmented),\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E19MnuFuToy"
      },
      "outputs": [],
      "source": [
        "# Check our model training curves\n",
        "plot_loss_curves(history_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa5NPCx8xurz"
      },
      "source": [
        "Let's shuffle our augmented training data and train another model(the same as before) on it and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXdNOYgRxj2P"
      },
      "outputs": [],
      "source": [
        "# Import data and augment it and shuffle from training directory\n",
        "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                            target_size=(224,224),\n",
        "                                                                            class_mode=\"binary\",\n",
        "                                                                            batch_size=32,\n",
        "                                                                            shuffle=True) # shuffle data this time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ4aNVEf0_sh"
      },
      "outputs": [],
      "source": [
        "# Create the model(same as model_5 and model_6)\n",
        "model_7 = Sequential([\n",
        "    Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10,3,activation = \"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_7 = model_7.fit(train_data_augmented_shuffled, # now the augmented data is shuffled\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented_shuffled),\n",
        "                        validation_data= test_data,\n",
        "                        validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrWdL4Oj8fkD"
      },
      "outputs": [],
      "source": [
        "# check model's performance history training on augmented data\n",
        "plot_loss_curves(history_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-608TvKN9tpF"
      },
      "source": [
        "### 7. Repeat untill satisfied\n",
        "Since we've already beaten our baseline,there are a few things we could try to continue to improve our model:\n",
        "* Increase the number of model layers(e.g. add more `Conv2D`/`MaxPool2D` layers)\n",
        "* Increase the number of filters in each convolutional layer(e.e 10 to 32 even 64)\n",
        "* Train for longer\n",
        "* Find an ideal rate\n",
        "* Get more data (given the model more oppurtunities to learn)\n",
        "* Use **tranfer learning** to leverage what another model has learnt and adjust it for our own use case.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqTFp5v3E1oW"
      },
      "source": [
        "## Making a prediction with our tarined model on our custom data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1Z5mfNJv-o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wil9ffcmFOj_"
      },
      "outputs": [],
      "source": [
        "# classes we're working with\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxECRtcFJoCh"
      },
      "outputs": [],
      "source": [
        "# View our example image\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
        "steak = mpimg.imread(\"03-steak.jpeg\")\n",
        "plt.imshow(steak)\n",
        "plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIJ3xZGJa3EW"
      },
      "outputs": [],
      "source": [
        "# check the shape of our image\n",
        "steak.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5fWFtSvbkAG"
      },
      "outputs": [],
      "source": [
        "steak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJoN8la1cLNG"
      },
      "source": [
        "> ðŸ”‘**Note:**when you train a neural network and you want to make prediction with it on your own custom data,it's important that your custom data(or new data) is preprocessed into the same format as tha data your model is trained on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ63HeqHcyXt"
      },
      "outputs": [],
      "source": [
        "# create a function to import and reshape the image to be able to be used with our model\n",
        "def load_and_prep_image(filename,img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename,turns it into a tensor and reshapes it to (img_shape,img,shape,colour_channels)\n",
        "  \"\"\"\n",
        "  # read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # decode the read fiel into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "\n",
        "  # # resize the image\n",
        "  img = tf.image.resize(img,size=[img_shape,img_shape])\n",
        "\n",
        "  # rescale the image(get all values between 0 & 1)\n",
        "  img = img/255.\n",
        "\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgzu1tWmcEYV"
      },
      "outputs": [],
      "source": [
        "# load in and preprocess our custyom image\n",
        "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
        "steak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIEsXz7dblHH"
      },
      "outputs": [],
      "source": [
        "pred =model_7.predict(tf.expand_dims(steak,axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwZg4XYIf3g5"
      },
      "source": [
        "Looks like our custom image is being put through our model,however,it currently outputs a prediction probability,wouldn't it be nice if we could visualize the image as well as the model's prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnFa4xXIb2jG"
      },
      "outputs": [],
      "source": [
        "# remind ourselves of our class names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsMrh0P5gazy"
      },
      "outputs": [],
      "source": [
        "# we can index the predicted class by rounding the prediction probability and indexing it on the class names\n",
        "pred_class = class_names[int(tf.round(pred))]\n",
        "pred_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3E7Bskxgqzc"
      },
      "outputs": [],
      "source": [
        "def pred_and_plot(model,filename,class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename,makes a prediction with model and\n",
        "  plots the image with the predicted class as the title\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction:{pred_class}\")\n",
        "  plt.axis(False);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj7U2IkUlz62"
      },
      "outputs": [],
      "source": [
        "# test our model on a custom image\n",
        "pred_and_plot(model_7,\"03-steak.jpeg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL_XBTramPU-"
      },
      "source": [
        "our model works! let's try it on another image..this time pizza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-x7j368l9je"
      },
      "outputs": [],
      "source": [
        "# Download another test image and make a prediction on it\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
        "pred_and_plot(model_7, \"03-pizza-dad.jpeg\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO8dF6-unUIq"
      },
      "source": [
        "## Multi-class Image Classification\n",
        "\n",
        "We've just been through a bunch of following steps with a binary classification problem(pizz vs. steak),now we're going to step things up in notch with 10 classes of food( multi-class classification).\n",
        "\n",
        "1. Become one with data\n",
        "2. Preprocess the data(get it ready for model)\n",
        "3. Create a model(start with baseline)\n",
        "4. Fit the model(overfit it to make it sure it works)\n",
        "5. Evaluate the model\n",
        "6. Adjust different hyperparameters and improve the model(try to beat baseline/reduce overfitting)\n",
        "7. Repeat untill satisfied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2oHoKldkh9u"
      },
      "source": [
        "## 1. Import and Become one with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtIHaEFUmJZ-"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file of 10_food_classes images\n",
        "# See how this data was created - https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHt_gC3amsa8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# walk through 10 claasses of food image data\n",
        "for dirpath,dirnames,filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIpSq0F4vtZS"
      },
      "outputs": [],
      "source": [
        "!ls -la 10_food_classes_all_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnHnZrEIv2_s"
      },
      "outputs": [],
      "source": [
        "# setup the train and test directories\n",
        "train_dir =\"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVhWifedwXRY"
      },
      "outputs": [],
      "source": [
        "# Let's get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir =pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFgDWXVA1JyN"
      },
      "outputs": [],
      "source": [
        "# visualize visualize visualize\n",
        "import random\n",
        "img = view_random_image(target_dir = train_dir,\n",
        "                        target_class =random.choice(class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EE3dSZ11hhp"
      },
      "source": [
        "### 2. Preprocess the data(prepare it for a model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AufBubH22VUg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Load data in form of directoriesand turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size = (224,224),\n",
        "                                               batch_size =32,\n",
        "                                               class_mode = \"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = (224,224),\n",
        "                                             batch_size= 32,\n",
        "                                             class_mode = \"categorical\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSiuySfe2jAs"
      },
      "source": [
        "### 3. Create a model(start ewith baseline)\n",
        "\n",
        "We've been talking lot about [CNN Explainer](https://https://poloclub.github.io/cnn-explainer/) website....how about we just take their model(also on 10 classes) and use it for our problem\n",
        "\n",
        "We can use the same model (TinyVGG) we used for the binary classification problem for our multi-class classification problem with a couple of small tweaks.\n",
        "\n",
        "Namely:\n",
        "* Changing the output layer to use have 10 ouput neurons (the same number as the number of classes we have).\n",
        "* Changing the output layer to use `'softmax'` activation instead of `'sigmoid'` activation.\n",
        "* Changing the loss function to be `'categorical_crossentropy'` instead of `'binary_crossentropy'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkj03mzCV1Df"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "# Create our model (a clone of model_8, except to be multi-class)\n",
        "model_9 = Sequential([\n",
        "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax') # changed to have 10 neurons (same as number of classes) and 'softmax' activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\", # changed to categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fit a model\n",
        "\n",
        "Now we've got a model suited for working with multiple classes,let's fir ir to our data."
      ],
      "metadata": {
        "id": "PV_Lh8e3JV3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_9 = model_9.fit(train_data,# now 10 different classes\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "qcxsorkFKFH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluate a model\n",
        "\n",
        "We've just trained a model on 10 different classes of food images,let's see how it went"
      ],
      "metadata": {
        "id": "fBFT2_VCKwSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test data\n",
        "model_9.evaluate(test_data)"
      ],
      "metadata": {
        "id": "kjpvnlxuNI3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the model's loss curve on the 10 classes of  data\n",
        "plot_loss_curves(history_9)"
      ],
      "metadata": {
        "id": "TNE_fpz6NOdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woah, that's quite the gap between the training and validation loss curves.\n",
        "\n",
        "What does this tell us?\n",
        "\n",
        "It seems our model is **overfitting** the training set quite badly. In other words, it's getting great results on the training data but fails to generalize well to unseen data and performs poorly on the test data."
      ],
      "metadata": {
        "id": "GB2B8reHNnoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Adjust the model parameters\n",
        "\n",
        "Due to its performance on the training data, it's clear our model is learning something. However, performing well on the training data is like going well in the classroom but failing to use your skills in real life.\n",
        "\n",
        "Ideally, we'd like our model to perform as well on the test data as it does on the training data.\n",
        "\n",
        "So our next steps will be to try and prevent our model overfitting. A couple of ways to prevent overfitting include:\n",
        "\n",
        "- **Get more data** - Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples.\n",
        "- **Simplify model** - If the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer.\n",
        "- **Use data augmentation** - Data augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data.\n",
        "- **Use transfer learning** - Transfer learning involves leverages the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images.\n",
        "\n",
        "> ðŸ”‘ **Note:** Preventing overfitting is also referred to as **regularization**.\n",
        "\n",
        "If you've already got an existing dataset, you're probably most likely to try one or a combination of the last three above options first.\n",
        "\n",
        "Since collecting more data would involve us manually taking more images of food, let's try the ones we can do from right within the notebook.\n",
        "\n",
        "How about we simplify our model first?\n",
        "\n",
        "To do so, we'll remove two of the convolutional layers, taking the total number of convolutional layers from four to two.\n",
        "\n"
      ],
      "metadata": {
        "id": "f98fm7v6NZ65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY simplified model( remove two layers)\n",
        "model_10 = Sequential([\n",
        "    Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10,3,activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_10.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "history_10 = model_10.fit(train_data,\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch = len(train_data),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "WMNgGmrcNygK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out loss curves of model_10\n",
        "plot_loss_curves(history_10)"
      ],
      "metadata": {
        "id": "fNmf0rcSbxnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm... even with a simplifed model, it looks like our model is still dramatically overfitting the training data.\n",
        "\n",
        "What else could we try?\n",
        "\n",
        "How about **data augmentation**?\n",
        "\n",
        "Data augmentation makes it harder for the model to learn on the training data and in turn, hopefully making the patterns it learns more generalizable to unseen data.\n",
        "\n",
        "To create augmented data, we'll recreate a new [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) instance, this time adding some parameters such as `rotation_range` and `horizontal_flip` to manipulate our images."
      ],
      "metadata": {
        "id": "D08KhXErO87v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create augmented data generator instance\n",
        "train_datagen_augmented= ImageDataGenerator(rescale=1/255.,\n",
        "                                            rotation_range=20, # note: this is  int not float\n",
        "                                            width_shift_range=0.2,\n",
        "                                            height_shift_range=0.2,\n",
        "                                            zoom_range=0.2,horizontal_flip=True)\n",
        "\n",
        "train_data_augmented= train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                  target_size=(224,224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "JGEVfOypRyEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got augmented data, let's see how it works with the same model as before (`model_10`).\n",
        "\n",
        "Rather than rewrite the model from scratch, we can clone it using a handy function in TensorFlow called [`clone_model`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model) which can take an existing model and rebuild it in the same format.\n",
        "\n",
        "The cloned version will not include any of the weights (patterns) the original model has learned. So when we train it, it'll be like training a model from scratch.\n",
        "> ðŸ”‘ **Note:** One of the key practices in deep learning and machine learning in general is to **be a serial experimenter**. That's what we're doing here. Trying something, seeing if it works, then trying something else. A good experiment setup also keeps track of the things you change, for example, that's why we're using the same model as before but with different data. The model stays the same but the data changes, this will let us know if augmented training data has any influence over performance."
      ],
      "metadata": {
        "id": "lWn43dowTAQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the model(use the same architecture)\n",
        "model_11 = tf.keras.models.clone_model(model_10)\n",
        "\n",
        "# Compile the cloned model (same setup as used for model_10)\n",
        "model_11.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_11 = model_11.fit(train_data_augmented, # use augmented data\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "K6L-OHYykw4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see it each epoch takes longer than the previous model. This is because our data is being augmented on the fly on the CPU as it gets loaded onto the GPU, in turn, increasing the amount of time between each epoch.\n",
        "\n",
        "> **Note:** One way to improve this time taken is to use augmentation layers directly as part of the model. For example, with [`tf.keras.layers.RandomFlip`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip). You can also speed up data loading with the newer [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) image loading API (we cover this later in the course).\n",
        "\n",
        "How do our model's training curves look?"
      ],
      "metadata": {
        "id": "btI44zKOdvO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checjk out our model's performance with augmented data\n",
        "plot_loss_curves(history_11)"
      ],
      "metadata": {
        "id": "JUUT0mqojTnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's looking much better, the loss curves are much closer to eachother. Although our model didn't perform as well on the augmented training set, it performed much better on the validation dataset.\n",
        "\n",
        "It even looks like if we kept it training for longer (more epochs) the evaluation metrics might continue to improve."
      ],
      "metadata": {
        "id": "hyMMIvJnjb17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Repeat until satisfied\n",
        "\n",
        "We could keep going here. Restructuring our model's architecture, adding more layers, trying it out, adjusting the learning rate, trying it out, trying different methods of data augmentation, training for longer. But as you could image, this could take a fairly long time.\n",
        "\n",
        "Good thing there's still one trick we haven't tried yet and that's **transfer learning**.\n",
        "\n",
        "However, we'll save that for the next notebook where you'll see how rather than design our own models from scratch we leverage the patterns another model has learned for our own task.\n",
        "\n",
        "In the meantime, let's make a prediction with our trained multi-class model."
      ],
      "metadata": {
        "id": "uoYoa5mOjiB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction with our trained model\n",
        "\n",
        "What good is a model if you can't make predictions with it?\n",
        "\n",
        "Let's first remind ourselves of the classes our multi-class model has been trained on and then we'll download some of own custom images to work with."
      ],
      "metadata": {
        "id": "ve9Lhfc4jmcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what classes has our model been trained on?\n",
        "class_names"
      ],
      "metadata": {
        "id": "Qx4_70Rbj-gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful, now let's get some of our custom images.\n",
        "\n",
        "If you're using Google Colab, you could also upload some of your own images via the files tab."
      ],
      "metadata": {
        "id": "dp8IvJc9kE0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some custom images\n",
        "# -q is for \"quiet\"\n",
        "!wget -q https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
        "!wget -q https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
        "!wget -q https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-hamburger.jpeg\n",
        "!wget -q https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-sushi.jpeg"
      ],
      "metadata": {
        "id": "acv6MuKakKsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model,filename,class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename,makes a prediction with model and\n",
        "  plots the image with the predicted class as the title\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  #print(len(pred[0]))\n",
        " # print(tf.argmax(pred))\n",
        "\n",
        "  # Add in logic for multi-class & get pred_class name\n",
        "  if len(pred[0])>1:\n",
        "    pred_class= class_names[tf.argmax(pred[0])]\n",
        "  else:\n",
        "    pred_class= class_names[int(tf.argmax(pred[0]))]\n",
        "\n",
        "  # Get the predicted class\n",
        "  #pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction:{pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "-51M7_Y5meG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make our prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-pizza-dad.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "g49PPUJ5leKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make our prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-steak.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "ZaN0ZnT8mdDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make our prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-sushi.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "gGwc-1nNoo18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make our prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-hamburger.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "BrhSjUwnoxhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# saving and loading a model"
      ],
      "metadata": {
        "id": "HCuy-5rco36B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save a model\n",
        "model_10.save(\"saved_trained_model_10\")"
      ],
      "metadata": {
        "id": "fPESmtlwpkLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in a trained model and evaluate\n",
        "loaded_model_10=tf.keras.models.load_model(\"saved_trained_model_10\")\n",
        "loaded_model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Tk1FSRtbpqVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare our loaded model to our existing model\n",
        "model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "M9W_HoS2qAW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KJQzfMn8qI30"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}